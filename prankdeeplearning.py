# -*- coding: utf-8 -*-
"""PrankDeepLearning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g9VXJbnqVBS-n7MBOC7YuWwt6g1O-7yl
"""

# Commented out IPython magic to ensure Python compatibility.
import pickle
import IPython
import os
from matplotlib import pyplot
import librosa
import pandas as pd
import datetime
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import IPython.display as ipd
import librosa.display
import scipy
import glob
import numpy as np
import math
import warnings
import pickle
from sklearn.utils import shuffle
import zipfile
import pickle
import IPython
import os
from matplotlib import pyplot
import numpy as np
import torch
# Load the TensorBoard notebook extension.
# %load_ext tensorboard

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

os.chdir('/content/drive/MyDrive/DeepLearning')

tf.random.set_seed(999)
np.random.seed(999)

with open('denoise_dataset.pkl', 'rb') as f:
    data = pickle.load(f)

with open('data_11k.pickle' ,'rb') as g:
    data_11k = pickle.load(g)

with open('data_5k.pickle' ,'rb') as g:
    data_5k = pickle.load(g)

"""Downsample the data"""

from librosa import resample
# clean data downsampled to 5k
data_5k = librosa.resample(data[0], 11000, 5500, res_type='kaiser_best', fix=True, scale=False)

#Saving the downsampled data as a pickle file
pick_insert = open('/content/drive/MyDrive/DeepLearning/data_5k.pickle','wb')
pickle.dump(data_5k, pick_insert)
pick_insert.close()

"""Spectogram"""

# Commented out IPython magic to ensure Python compatibility.
data_5k.shape
data_11k.shape

# %matplotlib inline 
pyplot.plot(data_5k[0])

ndata = data[1]
for i in range(len(ndata)):
  ndata[i] /= np.max(np.abs(ndata[i]),axis=0)

print(ndata.shape)
pyplot.plot(ndata[0]);
#pyplot.plot(data_5k[0]);

"""FFT"""

fft_clean = np.fft.fft(data_5k[0])
magnitude_clean = np.abs(fft_clean)
frequency_clean = np.linspace(0,11000, len(magnitude_clean))

fft_noise = np.fft.fft(ndata)
magnitude_noise = np.abs(fft_noise)
frequency_noise = np.linspace(0,11000, len(magnitude_noise))

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline 
fig, ax = pyplot.subplots(ncols = 2)

pyplot.plot(frequency_clean, magnitude_clean)
pyplot.xlim(0,5500)
pyplot.title('Freqency spectrum');

pyplot.xlabel('Frequency (Hz)')

"""Train/Test Split"""

import pandas as pd

#train test split with tensorflow

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print('Using {} device'.format(device))

x = pd.DataFrame(ndata)
y = pd.DataFrame(data_5k)

x_train = x.sample(frac=0.7, random_state=25)
x_test = x.drop(x_train.index)

y_train = y.sample(frac=0.7, random_state=25)
y_test = y.drop(y_train.index)

#x_train = np.transpose(x_train)
#y_train = np.transpose(y_train)

x_train = tf.convert_to_tensor(np.array(x_train))
x_test = tf.convert_to_tensor(np.array(x_test))
y_train = tf.convert_to_tensor(np.array(y_train))
y_test = tf.convert_to_tensor(np.array(y_test))

print(x_train.dtype)
print(x_train.shape)
print(x_test.shape)

print(f"No. of training examples: {x_train.shape[0]}")
print(f"No. of testing examples: {x_test.shape[0]}")

print(f"No. of training examples: {y_train.shape[0]}")
print(f"No. of testing examples: {y_test.shape[0]}")

def get_dataset(x_train,y_train):
  dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))
  dataset = dataset.shuffle(100).batch(64,drop_remainder=True)
  return dataset
  
train_dataset = get_dataset(x_train,y_train)
test_dataset = get_dataset(x_test,y_test)

import tensorflow as tf
from tensorflow.keras.layers import Conv1D,Conv1DTranspose,Concatenate,Input
import numpy as np
import IPython.display
import glob
from tqdm.notebook import tqdm
import librosa.display
import matplotlib.pyplot as plt

#batching_size = 6720

c1 = Conv1D(2,32,2,'same',activation='relu')(inp)
c2 = Conv1D(4,32,2,'same',activation='relu')(c1)
c3 = Conv1D(8,32,2,'same',activation='relu')(c2)
c4 = Conv1D(16,32,2,'same',activation='relu')(c3)
c5 = Conv1D(32,32,2,'same',activation='relu')(c4)

dc1 = Conv1DTranspose(32,32,1,padding='same')(c5)
conc = Concatenate()([c5,dc1])
dc2 = Conv1DTranspose(16,32,2,padding='same')(conc)
conc = Concatenate()([c4,dc2])
dc3 = Conv1DTranspose(8,32,2,padding='same')(conc)
conc = Concatenate()([c3,dc3])
dc4 = Conv1DTranspose(4,32,2,padding='same')(conc)
conc = Concatenate()([c2,dc4])
dc5 = Conv1DTranspose(2,32,2,padding='same')(conc)
conc = Concatenate()([c1,dc5])
dc6 = Conv1DTranspose(1,32,2,padding='same')(conc)
conc = Concatenate()([inp,dc6])
dc7 = Conv1DTranspose(1,32,1,padding='same',activation='linear')(conc)
model = tf.keras.models.Model(inp,dc7)
model.summary()

tf.keras.utils.plot_model(model,show_shapes=True,show_layer_names=False)

model.compile(optimizer=tf.keras.optimizers.Adam(0.002),loss=tf.keras.losses.MeanAbsoluteError())
history = model.fit(train_dataset,epochs=20)